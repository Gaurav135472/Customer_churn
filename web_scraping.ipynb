{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_path = r'C:\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe'\n",
    "url = 'https://ca.trustpilot.com/review/www.amazon.com'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Options' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m driver_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mchromedriver-win64\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mchromedriver-win64\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mchromedriver.exe\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Set Chrome options\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m chrome_options \u001b[38;5;241m=\u001b[39m \u001b[43mOptions\u001b[49m()\n\u001b[0;32m      6\u001b[0m chrome_options\u001b[38;5;241m.\u001b[39madd_argument(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--headless\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Optional: run in headless mode\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Initialize the Selenium WebDriver\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Options' is not defined"
     ]
    }
   ],
   "source": [
    "# Driver path\n",
    "driver_path = r'C:\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe'\n",
    "\n",
    "# Set Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Optional: run in headless mode\n",
    "\n",
    "# Initialize the Selenium WebDriver\n",
    "service = Service(driver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# Target URL (Amazon Reviews on Trustpilot)\n",
    "url = 'https://ca.trustpilot.com/review/www.amazon.com'\n",
    "\n",
    "# Open the URL\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the reviews container to load\n",
    "wait = WebDriverWait(driver, 10)\n",
    "\n",
    "# List to store the extracted reviews\n",
    "review_data = []\n",
    "\n",
    "# Recursive scroll function\n",
    "def scroll_page(scroll_count, max_scrolls):\n",
    "    try:\n",
    "        # Re-fetch the reviews container to avoid stale element\n",
    "        reviews_container = wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"styles_reviewsContainer__3_GQw\")))\n",
    "\n",
    "        # Scroll to the reviews container\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", reviews_container)\n",
    "        time.sleep(2)  # Adjust sleep if necessary to allow reviews to load\n",
    "\n",
    "        # Get the page source and parse with BeautifulSoup after scrolling\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        # Find all review containers on the page (updated class selector)\n",
    "        reviews = soup.find_all('div', {'class': 'styles_reviewCard__9HxJJ'})\n",
    "\n",
    "        # Print the number of reviews found in this scroll\n",
    "        print(f\"Number of reviews found: {len(reviews)}\")\n",
    "\n",
    "        # Extract the review text, rating, and consumer details for each review\n",
    "        for review in reviews:\n",
    "            try:\n",
    "                consumer_info = review.find('aside', {'class': 'styles_consumerInfoWrapper__KP3Ra'})\n",
    "\n",
    "                # Find the details wrapper within the consumer info\n",
    "                consumer_details = consumer_info.find('div', {'class': 'styles_consumerDetailsWrapper__p2wdr'})\n",
    "\n",
    "                # Extract the consumer name\n",
    "                consumer_name = consumer_details.find('a').find('span', {'class': 'typography_heading-xxs__QKBS8 typography_appearance-default__AAY17'}).text\n",
    "\n",
    "                # Extract consumer review number (handle missing elements)\n",
    "                consumer_review_no_element = consumer_details.find('div', {'class':'styles_consumerExtraDetails__fxS4S'}).find('span', 'typography_body-m__xgxZ_ typography_appearance-subtle__8_H2l')\n",
    "                consumer_review_no = consumer_review_no_element.text if consumer_review_no_element else 'Not Available'\n",
    "\n",
    "                # Extract consumer country (handle missing elements)\n",
    "                consumer_country_element = consumer_details.find('div', {'class':'styles_consumerExtraDetails__fxS4S'}).find('div', 'typography_body-m__xgxZ_ typography_appearance-subtle__8_H2l styles_detailsIcon__Fo_ua')\n",
    "                consumer_country = consumer_country_element.find('span').text if consumer_country_element else 'Not Available'\n",
    "\n",
    "                consumer_review_info = review.find('section', {'class':'styles_reviewContentwrapper__zH_9M'})\n",
    "\n",
    "                consumer_rating = consumer_review_info.find('div', {'class':'styles_reviewHeader__iU9Px'}).find('div', {'class': 'star-rating_starRating__4rrcf star-rating_medium__iN6Ty'}).find('img')\n",
    "                rating_text = consumer_rating.get('alt')\n",
    "\n",
    "                review_uploaded = consumer_review_info.find('div', {'class':'styles_reviewHeader__iU9Px'}).find('div', {'class': 'typography_body-m__xgxZ_ typography_appearance-subtle__8_H2l styles_datesWrapper__RCEKH'}).find('time')\n",
    "                review_uploaded_info = review_uploaded.get('title')\n",
    "\n",
    "                review_heading = review.find('div', {'class':'styles_reviewContent__0Q2Tg'}).find('a', {'class':'link_internal__7XN06 typography_appearance-default__AAY17 typography_color-inherit__TlgPO link_link__IZzHN link_notUnderlined__szqki'}).find('h2', {'class':'typography_heading-s__f7029 typography_appearance-default__AAY17'}).text\n",
    "\n",
    "                review_para = review.find('div', {'class':'styles_reviewContent__0Q2Tg'}).find('p', {'class':'typography_body-l__KUYFJ typography_appearance-default__AAY17 typography_color-black__5LYEn'}).text\n",
    "\n",
    "                # Print the extracted details\n",
    "                print(f\"Consumer Name: {consumer_name}\")\n",
    "                print(f'Consumer Review Number: {consumer_review_no}' )\n",
    "                print(f'Consumer Country: {consumer_country}')\n",
    "                print(\"                                           \")\n",
    "                print(review_uploaded_info)\n",
    "                print(f'{rating_text}')\n",
    "                print(\"                        \")\n",
    "                print(review_heading)\n",
    "                print(review_para)\n",
    "                print(\"----------------------------------\")\n",
    "\n",
    "                # Add review details to the list\n",
    "                review_data.append({\n",
    "                    'consumer_name': consumer_name,\n",
    "                    'consumer_review': consumer_review_no,\n",
    "                    'consumer_country': consumer_country,\n",
    "                    'date': review_uploaded_info,\n",
    "                    'rating' : rating_text,\n",
    "                    'review_topic': review_heading,\n",
    "                    'review_content': review_para\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting review data: {e}\")\n",
    "\n",
    "        # If max scrolls have not been reached, click the 'Next' link\n",
    "        if scroll_count < max_scrolls:\n",
    "            try:\n",
    "                # Try to find the 'Next' link and scroll into view before clicking it\n",
    "                next_link = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"a.button_button__T34Lr.pagination-link_next__SDNU4\")))\n",
    "                \n",
    "                # Scroll the link into view\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_link)\n",
    "                time.sleep(2)  # Allow the page to settle after the scroll\n",
    "\n",
    "                # Try to click the link (either via standard click or JavaScript click if necessary)\n",
    "                try:\n",
    "                    next_link.click()  # Try normal click\n",
    "                except:\n",
    "                    # Fallback to JavaScript click if the normal click fails\n",
    "                    driver.execute_script(\"arguments[0].click();\", next_link)\n",
    "\n",
    "                print(\"Next page link clicked.\")\n",
    "                time.sleep(3)  # Wait for the next page of reviews to load\n",
    "\n",
    "                # After navigating to the next page, continue scrolling\n",
    "                scroll_page(scroll_count + 1, max_scrolls)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"No more pages or next link not found: {e}\")\n",
    "\n",
    "        else:\n",
    "            return\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error while scrolling: {e}\")\n",
    "        return\n",
    "\n",
    "# Start the scraping process\n",
    "scroll_page(scroll_count=0, max_scrolls=5)\n",
    "\n",
    "# Close the driver after all scrolling and reviews have been processed\n",
    "driver.quit()\n",
    "\n",
    "# Convert the list of reviews into a DataFrame\n",
    "df = pd.DataFrame(review_data)\n",
    "\n",
    "# Show the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save the reviews to a CSV file\n",
    "df.to_csv('amazon_reviews_trustpilot.csv', index=False)\n",
    "\n",
    "print(\"Scraping complete. Data saved to 'amazon_reviews_trustpilot.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "81e5cffba460ad297270a9c1a1cbdc87cdf5b0861349050531603234\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   consumer_name consumer_review consumer_country  \\\n",
      "0       Lucy Loo       8 reviews               GB   \n",
      "1  Jeffrey Bruce       5 reviews               GB   \n",
      "2           Jdub       7 reviews               US   \n",
      "3           Glyn       5 reviews               GB   \n",
      "4      Ninja Ape       9 reviews               DE   \n",
      "\n",
      "                                          date                  rating  \\\n",
      "0    Friday, October 11, 2024 at 09:57:32 a.m.  Rated 1 out of 5 stars   \n",
      "1  Thursday, October 10, 2024 at 05:09:02 p.m.  Rated 1 out of 5 stars   \n",
      "2  Thursday, October 10, 2024 at 05:26:49 p.m.  Rated 1 out of 5 stars   \n",
      "3  Thursday, October 10, 2024 at 07:22:45 p.m.  Rated 1 out of 5 stars   \n",
      "4  Wednesday, October 9, 2024 at 05:44:08 p.m.  Rated 1 out of 5 stars   \n",
      "\n",
      "                               review_topic  \\\n",
      "0                          Driver stealing    \n",
      "1  Amazon are quick enough to take payment…   \n",
      "2       Got severely ill of a supplement I…   \n",
      "3                   NO stars is too many!!!   \n",
      "4                         Amazon is useless   \n",
      "\n",
      "                                      review_content sentiment_score  \\\n",
      "0  As a family we order from Amazon almost daily....            -0.4   \n",
      "1  Amazon are quick enough to take payment for or...            -0.7   \n",
      "2  Got severely ill of a supplement I bought from...            -0.5   \n",
      "3  If I could give NO stars, I would!Ordered some...            -0.8   \n",
      "4  Amazon doesn't care about it's customers. The ...            -0.6   \n",
      "\n",
      "  sentiment_magnitude                                           entities  \\\n",
      "0                 3.2  family, one, Amazon, change, nothing, packages...   \n",
      "1                 2.2  Amazon, payment, orders, claim, worst, custome...   \n",
      "2                 3.6  supplement, product, store, ripoff, j., type, ...   \n",
      "3                 1.6  something, stars, Customer Service, driver, ea...   \n",
      "4                 4.1  Amazon, customers, something, something, issue...   \n",
      "\n",
      "                                   entity_sentiments review_class  \\\n",
      "0  [{'name': 'family', 'type': 'PERSON', 'salienc...     Negative   \n",
      "1  [{'name': 'Amazon', 'type': 'ORGANIZATION', 's...     Negative   \n",
      "2  [{'name': 'supplement', 'type': 'OTHER', 'sali...     Negative   \n",
      "3  [{'name': 'something', 'type': 'OTHER', 'salie...     Negative   \n",
      "4  [{'name': 'Amazon', 'type': 'ORGANIZATION', 's...     Negative   \n",
      "\n",
      "                                   positive_reasons  \\\n",
      "0    As a family we order from Amazon almost daily.   \n",
      "1                                                     \n",
      "2  Just steady outsourcing jobs to other countries.   \n",
      "3                                                     \n",
      "4                                                     \n",
      "\n",
      "                                    negative_reasons  \\\n",
      "0  Sadly we've had a change in our regular delive...   \n",
      "1  Amazon are quick enough to take payment for or...   \n",
      "2  Got severely ill of a supplement I bought from...   \n",
      "3  If I could give NO stars, I would!Ordered some...   \n",
      "4  Amazon doesn't care about it's customers. The ...   \n",
      "\n",
      "                                       syntax_tokens detected_language  \\\n",
      "0  [{'text': 'As', 'part_of_speech': 'ADP'}, {'te...                en   \n",
      "1  [{'text': 'Amazon', 'part_of_speech': 'NOUN'},...                en   \n",
      "2  [{'text': 'Got', 'part_of_speech': 'VERB'}, {'...                en   \n",
      "3  [{'text': 'If', 'part_of_speech': 'ADP'}, {'te...                en   \n",
      "4  [{'text': 'Amazon', 'part_of_speech': 'NOUN'},...                en   \n",
      "\n",
      "                                     classifications  \n",
      "0  [{'category': '/Shopping', 'confidence': 0.649...  \n",
      "1  [{'category': '/Shopping', 'confidence': 0.620...  \n",
      "2  [{'category': '/Business & Industrial', 'confi...  \n",
      "3                                                 []  \n",
      "4  [{'category': '/Shopping/Consumer Resources', ...  \n"
     ]
    }
   ],
   "source": [
    "from google.cloud import language_v1\n",
    "from google.oauth2 import service_account\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'amazon_reviews_trustpilot.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Path to your service account key file\n",
    "key_path = r\"C:\\ML\\neural-cirrus-437807-t9-29c137016ba4.json\"\n",
    "\n",
    "# Load credentials from the JSON file\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "\n",
    "# Initialize the Google NLP client with the credentials\n",
    "client = language_v1.LanguageServiceClient(credentials=credentials)\n",
    "\n",
    "# Function to analyze sentiment, entities, and other NLP features for a review\n",
    "def analyze_review(text):\n",
    "    # Prepare document\n",
    "    document = language_v1.Document(content=text, type_=language_v1.Document.Type.PLAIN_TEXT)\n",
    "    \n",
    "    # Get sentiment analysis\n",
    "    sentiment_response = client.analyze_sentiment(request={'document': document})\n",
    "    sentiment = sentiment_response.document_sentiment\n",
    "    \n",
    "    # Get sentence-level sentiment analysis\n",
    "    positive_sentences = []\n",
    "    negative_sentences = []\n",
    "    for sentence in sentiment_response.sentences:\n",
    "        sentence_sentiment = sentence.sentiment.score\n",
    "        if sentence_sentiment >= 0:\n",
    "            positive_sentences.append(sentence.text.content)\n",
    "        else:\n",
    "            negative_sentences.append(sentence.text.content)\n",
    "    \n",
    "    # Get entity sentiment analysis (entities and their sentiment)\n",
    "    entity_sentiment_response = client.analyze_entity_sentiment(request={'document': document})\n",
    "    entity_sentiments = []\n",
    "    for entity in entity_sentiment_response.entities:\n",
    "        entity_info = {\n",
    "            'name': entity.name,\n",
    "            'type': language_v1.Entity.Type(entity.type_).name,\n",
    "            'salience': entity.salience,\n",
    "            'sentiment_score': entity.sentiment.score,\n",
    "            'sentiment_magnitude': entity.sentiment.magnitude\n",
    "        }\n",
    "        entity_sentiments.append(entity_info)\n",
    "\n",
    "    # Get syntax analysis (extracting part-of-speech tokens)\n",
    "    syntax_response = client.analyze_syntax(request={'document': document})\n",
    "    syntax_tokens = []\n",
    "    for token in syntax_response.tokens:\n",
    "        token_info = {\n",
    "            'text': token.text.content,\n",
    "            'part_of_speech': language_v1.PartOfSpeech.Tag(token.part_of_speech.tag).name\n",
    "        }\n",
    "        syntax_tokens.append(token_info)\n",
    "\n",
    "    # Detect language (useful if working with multilingual reviews)\n",
    "    language_response = client.analyze_entities(request={'document': document})\n",
    "    detected_language = language_response.language\n",
    "\n",
    "    # Classify text (optional, if you have text classification enabled)\n",
    "    try:\n",
    "        classify_response = client.classify_text(request={'document': document})\n",
    "        classifications = []\n",
    "        for category in classify_response.categories:\n",
    "            classifications.append({\n",
    "                'category': category.name,\n",
    "                'confidence': category.confidence\n",
    "            })\n",
    "    except Exception as e:\n",
    "        classifications = []\n",
    "    \n",
    "    # Classify review as positive or negative based on the overall sentiment score\n",
    "    review_class = 'Positive' if sentiment.score >= 0 else 'Negative'\n",
    "    \n",
    "    return {\n",
    "        'sentiment_score': sentiment.score,\n",
    "        'sentiment_magnitude': sentiment.magnitude,\n",
    "        'entities': [entity['name'] for entity in entity_sentiments],\n",
    "        'entity_sentiments': entity_sentiments,\n",
    "        'review_class': review_class,\n",
    "        'positive_reasons': \" \".join(positive_sentences),\n",
    "        'negative_reasons': \" \".join(negative_sentences),\n",
    "        'syntax_tokens': syntax_tokens,\n",
    "        'detected_language': detected_language,\n",
    "        'classifications': classifications\n",
    "    }\n",
    "\n",
    "# Add columns for sentiment score, entity sentiment, classification, language detection, syntax tokens, etc.\n",
    "df['sentiment_score'] = None\n",
    "df['sentiment_magnitude'] = None\n",
    "df['entities'] = None\n",
    "df['entity_sentiments'] = None\n",
    "df['review_class'] = None\n",
    "df['positive_reasons'] = None\n",
    "df['negative_reasons'] = None\n",
    "df['syntax_tokens'] = None\n",
    "df['detected_language'] = None\n",
    "df['classifications'] = None\n",
    "\n",
    "# Analyze each review\n",
    "for i, row in df.iterrows():\n",
    "    review_text = row['review_content']\n",
    "    analysis_result = analyze_review(review_text)\n",
    "    \n",
    "    df.at[i, 'sentiment_score'] = analysis_result['sentiment_score']\n",
    "    df.at[i, 'sentiment_magnitude'] = analysis_result['sentiment_magnitude']\n",
    "    df.at[i, 'entities'] = \", \".join(analysis_result['entities'])\n",
    "    df.at[i, 'entity_sentiments'] = analysis_result['entity_sentiments']\n",
    "    df.at[i, 'review_class'] = analysis_result['review_class']\n",
    "    df.at[i, 'positive_reasons'] = analysis_result['positive_reasons']\n",
    "    df.at[i, 'negative_reasons'] = analysis_result['negative_reasons']\n",
    "    df.at[i, 'syntax_tokens'] = analysis_result['syntax_tokens']\n",
    "    df.at[i, 'detected_language'] = analysis_result['detected_language']\n",
    "    df.at[i, 'classifications'] = analysis_result['classifications']\n",
    "\n",
    "# Save the updated dataset with all the NLP analysis\n",
    "output_file = 'amazon_reviews_with_full_nlp_analysis.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "# Display the first few rows of the updated dataframe\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
