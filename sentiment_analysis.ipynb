{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   unnamed:_0               name  review  \\\n",
      "0           0  Vladimiro Mascaro     3.0   \n",
      "1           1           Lucy Loo     9.0   \n",
      "2           2                 Da    21.0   \n",
      "3           3        Vicki Study     1.0   \n",
      "4           4      Jeffrey Bruce     5.0   \n",
      "\n",
      "                                      date_old  rating company  \\\n",
      "0    Friday, October 11, 2024 at 06:25:37 p.m.       1  amazon   \n",
      "1    Friday, October 11, 2024 at 09:57:32 a.m.       1  amazon   \n",
      "2  Thursday, October 10, 2024 at 11:36:09 a.m.       5  amazon   \n",
      "3    Friday, October 11, 2024 at 03:36:33 p.m.       1  amazon   \n",
      "4  Thursday, October 10, 2024 at 05:09:02 p.m.       1  amazon   \n",
      "\n",
      "          country                 date  \\\n",
      "0  United Kingdom  2024-10-01 18:25:37   \n",
      "1  United Kingdom  2024-10-01 09:57:32   \n",
      "2  United Kingdom  2024-10-01 11:36:09   \n",
      "3  United Kingdom  2024-10-01 15:36:33   \n",
      "4  United Kingdom  2024-10-01 17:09:02   \n",
      "\n",
      "                                     topic  \\\n",
      "0            4 months of total incopetence   \n",
      "1                         driver stealing    \n",
      "2      where is the negativity coming from   \n",
      "3   absolutely appalling customer service    \n",
      "4  amazon are quick enough to take payment   \n",
      "\n",
      "                                             content sentiment_score  \\\n",
      "0  since july until this month of all my orders 8...            -0.6   \n",
      "1  as a family we order from amazon almost daily ...            -0.8   \n",
      "2  probably the only store that 1 delivers ontime...             0.1   \n",
      "3  the customer service has been absolutely appal...            -0.7   \n",
      "4  amazon are quick enough to take payment for or...            -0.7   \n",
      "\n",
      "  sentiment_magnitude                                           entities  \\\n",
      "0                 0.6  orders, orders, thing, direct debit, headphone...   \n",
      "1                 0.8  amazon, family, change, one, nothing, packages...   \n",
      "2                 0.1  store, customers, prices, competitors, valuefo...   \n",
      "3                 0.7  customer service, calls, ive, fault, issue, am...   \n",
      "4                 0.7  amazon, payment, orders, worst, claim, custome...   \n",
      "\n",
      "                                   entity_sentiments review_class  \\\n",
      "0  [{'name': 'orders', 'type': 'OTHER', 'salience...     Negative   \n",
      "1  [{'name': 'amazon', 'type': 'ORGANIZATION', 's...     Negative   \n",
      "2  [{'name': 'store', 'type': 'LOCATION', 'salien...     Positive   \n",
      "3  [{'name': 'customer service', 'type': 'OTHER',...     Negative   \n",
      "4  [{'name': 'amazon', 'type': 'ORGANIZATION', 's...     Negative   \n",
      "\n",
      "                                    positive_reasons  \\\n",
      "0                                                      \n",
      "1                                                      \n",
      "2  probably the only store that 1 delivers ontime...   \n",
      "3                                                      \n",
      "4                                                      \n",
      "\n",
      "                                    negative_reasons  \\\n",
      "0  since july until this month of all my orders 8...   \n",
      "1  as a family we order from amazon almost daily ...   \n",
      "2                                                      \n",
      "3  the customer service has been absolutely appal...   \n",
      "4  amazon are quick enough to take payment for or...   \n",
      "\n",
      "                                       syntax_tokens detected_language  \\\n",
      "0  [{'text': 'since', 'part_of_speech': 'ADP'}, {...                en   \n",
      "1  [{'text': 'as', 'part_of_speech': 'ADP'}, {'te...                en   \n",
      "2  [{'text': 'probably', 'part_of_speech': 'ADV'}...                en   \n",
      "3  [{'text': 'the', 'part_of_speech': 'DET'}, {'t...                en   \n",
      "4  [{'text': 'amazon', 'part_of_speech': 'NOUN'},...                en   \n",
      "\n",
      "                                     classifications  \n",
      "0  [{'category': '/Shopping', 'confidence': 0.629...  \n",
      "1                                                 []  \n",
      "2                                                 []  \n",
      "3                                                 []  \n",
      "4  [{'category': '/Shopping', 'confidence': 0.629...  \n"
     ]
    }
   ],
   "source": [
    "from google.cloud import language_v1\n",
    "from google.oauth2 import service_account\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your CSV file and service account key file\n",
    "file_path = r'amazon_reviews_cleaned.csv'  # Use absolute path\n",
    "key_path = r\"C:\\ML\\neural-cirrus-437807-t9-29c137016ba4.json\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Strip column names to remove extra spaces or characters\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Check if the expected column 'content' exists\n",
    "if 'content' not in df.columns:\n",
    "    raise KeyError(\"'content' column not found in the dataset\")\n",
    "\n",
    "# Load credentials from the JSON file\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "\n",
    "# Initialize the Google NLP client with the credentials\n",
    "client = language_v1.LanguageServiceClient(credentials=credentials)\n",
    "\n",
    "# Function to analyze sentiment, entities, and other NLP features for a review\n",
    "def analyze_review(text):\n",
    "    if not text or pd.isna(text):\n",
    "        return {\n",
    "            'sentiment_score': None,\n",
    "            'sentiment_magnitude': None,\n",
    "            'entities': [],\n",
    "            'entity_sentiments': [],\n",
    "            'review_class': None,\n",
    "            'positive_reasons': \"\",\n",
    "            'negative_reasons': \"\",\n",
    "            'syntax_tokens': [],\n",
    "            'detected_language': None,\n",
    "            'classifications': []\n",
    "        }\n",
    "    \n",
    "    # Prepare document\n",
    "    document = language_v1.Document(content=text, type_=language_v1.Document.Type.PLAIN_TEXT)\n",
    "    \n",
    "    # Get sentiment analysis\n",
    "    sentiment_response = client.analyze_sentiment(request={'document': document})\n",
    "    sentiment = sentiment_response.document_sentiment\n",
    "    \n",
    "    # Get sentence-level sentiment analysis\n",
    "    positive_sentences = []\n",
    "    negative_sentences = []\n",
    "    for sentence in sentiment_response.sentences:\n",
    "        sentence_sentiment = sentence.sentiment.score\n",
    "        if sentence_sentiment >= 0:\n",
    "            positive_sentences.append(sentence.text.content)\n",
    "        else:\n",
    "            negative_sentences.append(sentence.text.content)\n",
    "    \n",
    "    # Get entity sentiment analysis (entities and their sentiment)\n",
    "    entity_sentiment_response = client.analyze_entity_sentiment(request={'document': document})\n",
    "    entity_sentiments = []\n",
    "    for entity in entity_sentiment_response.entities:\n",
    "        entity_info = {\n",
    "            'name': entity.name,\n",
    "            'type': language_v1.Entity.Type(entity.type_).name,\n",
    "            'salience': entity.salience,\n",
    "            'sentiment_score': entity.sentiment.score,\n",
    "            'sentiment_magnitude': entity.sentiment.magnitude\n",
    "        }\n",
    "        entity_sentiments.append(entity_info)\n",
    "\n",
    "    # Get syntax analysis (extracting part-of-speech tokens)\n",
    "    syntax_response = client.analyze_syntax(request={'document': document})\n",
    "    syntax_tokens = []\n",
    "    for token in syntax_response.tokens:\n",
    "        token_info = {\n",
    "            'text': token.text.content,\n",
    "            'part_of_speech': language_v1.PartOfSpeech.Tag(token.part_of_speech.tag).name\n",
    "        }\n",
    "        syntax_tokens.append(token_info)\n",
    "\n",
    "    # Detect language (useful if working with multilingual reviews)\n",
    "    language_response = client.analyze_entities(request={'document': document})\n",
    "    detected_language = language_response.language\n",
    "\n",
    "    # Classify text (optional, if you have text classification enabled)\n",
    "    try:\n",
    "        classify_response = client.classify_text(request={'document': document})\n",
    "        classifications = []\n",
    "        for category in classify_response.categories:\n",
    "            classifications.append({\n",
    "                'category': category.name,\n",
    "                'confidence': category.confidence\n",
    "            })\n",
    "    except Exception as e:\n",
    "        classifications = []\n",
    "    \n",
    "    # Classify review as positive or negative based on the overall sentiment score\n",
    "    review_class = 'Positive' if sentiment.score >= 0 else 'Negative'\n",
    "    \n",
    "    return {\n",
    "        'sentiment_score': sentiment.score,\n",
    "        'sentiment_magnitude': sentiment.magnitude,\n",
    "        'entities': [entity['name'] for entity in entity_sentiments],\n",
    "        'entity_sentiments': entity_sentiments,\n",
    "        'review_class': review_class,\n",
    "        'positive_reasons': \" \".join(positive_sentences),\n",
    "        'negative_reasons': \" \".join(negative_sentences),\n",
    "        'syntax_tokens': syntax_tokens,\n",
    "        'detected_language': detected_language,\n",
    "        'classifications': classifications\n",
    "    }\n",
    "\n",
    "# Add columns for sentiment score, entity sentiment, classification, language detection, syntax tokens, etc.\n",
    "df['sentiment_score'] = None\n",
    "df['sentiment_magnitude'] = None\n",
    "df['entities'] = None\n",
    "df['entity_sentiments'] = None\n",
    "df['review_class'] = None\n",
    "df['positive_reasons'] = None\n",
    "df['negative_reasons'] = None\n",
    "df['syntax_tokens'] = None\n",
    "df['detected_language'] = None\n",
    "df['classifications'] = None\n",
    "\n",
    "# Analyze each review\n",
    "for i, row in df.iterrows():\n",
    "    review_text = row['content']  # Correct column name is 'content'\n",
    "    analysis_result = analyze_review(review_text)\n",
    "    \n",
    "    df.at[i, 'sentiment_score'] = analysis_result['sentiment_score']\n",
    "    df.at[i, 'sentiment_magnitude'] = analysis_result['sentiment_magnitude']\n",
    "    df.at[i, 'entities'] = \", \".join(analysis_result['entities'])\n",
    "    df.at[i, 'entity_sentiments'] = analysis_result['entity_sentiments']\n",
    "    df.at[i, 'review_class'] = analysis_result['review_class']\n",
    "    df.at[i, 'positive_reasons'] = analysis_result['positive_reasons']\n",
    "    df.at[i, 'negative_reasons'] = analysis_result['negative_reasons']\n",
    "    df.at[i, 'syntax_tokens'] = analysis_result['syntax_tokens']\n",
    "    df.at[i, 'detected_language'] = analysis_result['detected_language']\n",
    "    df.at[i, 'classifications'] = analysis_result['classifications']\n",
    "\n",
    "# Save the updated dataset with all the NLP analysis\n",
    "output_file = 'all_reviews_with_full_nlp_analysis.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "# Display the first few rows of the updated dataframe\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'name', 'review', 'date_old', 'rating', 'company',\n",
       "       'country', 'date', 'topic', 'content'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('amazon_reviews_cleaned.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
